#  Proyecto Integrador: Detecci贸n de Intrusiones en Redes de Comunicaci贸n

Este proyecto implementa y eval煤a t茅cnicas y algoritmos de aprendizaje autom谩tico para la detecci贸n de intrusiones en redes de comunicaci贸n. Nos enfocamos en una clasificaci贸n binaria: Tr谩fico de tipo Ataque y Tr谩fico Normal de Red.

##  Estructura del Proyecto

La estructura del repositorio es la siguiente:

- Carpeta `DataSet_UNSW_NB15` con los archivos CSV del conjunto de entrenamiento y conjunto de pruebas:
  - `DataSet_UNSW_NB15/UNSW_NB15_testing-set.csv`
  - `DataSet_UNSW_NB15/UNSW_NB15_training-set.csv`

- Dos archivos en Jupyter Notebook:

  1.  `Analisis_de_DataSet.ipynb` que incluye:
     - **Carga de datos**: Carga del conjunto de datos utilizando m茅todos como `pd.read_csv`.
     - **Visualizaci贸n de datos**: Generaci贸n de gr谩ficos y visualizaciones para entender mejor la distribuci贸n y las caracter铆sticas de los datos. Herramientas utilizadas incluyen `matplotlib` y `seaborn`.
     - **An谩lisis de datos**: An谩lisis exploratorio de los datos, describiendo las caracter铆sticas estad铆sticas y visualizando las primeras filas del conjunto de datos.

  2.  `ProyectoIntregradorUSFQ.ipynb` que incluye:
     - **Carga de datos**: Se cargan los conjuntos de datos de entrenamiento y prueba desde URLs en GitHub utilizando la funci贸n `cargar_datos`, que lee los archivos CSV y los convierte en dataframes de pandas.
     - **Visualizaci贸n y An谩lisis de datos**: Se combinan los conjuntos de datos de entrenamiento y prueba en un solo dataframe y se reinicia el 铆ndice. Se visualiza la estructura y contenido del dataframe combinado para obtener una visi贸n general de las columnas y tipos de datos.
     - **Eliminaci贸n de columnas no necesarias**: Se eliminan las columnas `service`, `proto` y `state`, ya que no son necesarias para el an谩lisis posterior.
     - **Transformaci贸n de la columna categ贸rica `attack_cat`**: Se convierte la columna `attack_cat` en c贸digos num茅ricos utilizando la funci贸n `pd.Categorical().codes`.
     - **Verificaci贸n de valores nulos**: Se verifica la presencia de valores nulos en el dataframe y se imprime el conteo de valores nulos por columna.
     - **Eliminaci贸n de columnas con alta correlaci贸n**: Se calcula la matriz de correlaci贸n absoluta del dataframe. Se identifican y eliminan las columnas con una correlaci贸n mayor a 0.95 para reducir la multicolinealidad.
     - **Preprocesamiento de datos**: Se identifican las columnas num茅ricas del dataframe que no incluyen la etiqueta `label`. Se normalizan las columnas num茅ricas utilizando `MinMaxScaler` para escalar los datos en un rango de 0 a 1.
     - **Divisi贸n del dataset**: Se separan las caracter铆sticas (`X`) y las etiquetas (`y`). Se divide el conjunto de datos en entrenamiento (70%) y prueba (30%) utilizando `train_test_split`. Se divide el conjunto de entrenamiento temporal en conjuntos de entrenamiento real y validaci贸n (20% del conjunto de entrenamiento).
     - **Visualizaci贸n de la distribuci贸n de las etiquetas**: Se visualiza la distribuci贸n de las etiquetas `label` (normal y ataque) utilizando un gr谩fico de pastel.
     - **Modelado**: Se realiza una b煤squeda de hiperpar谩metros para el modelo de 谩rbol de decisi贸n utilizando `GridSearchCV`. Se entrena el modelo de 谩rbol de decisi贸n con los mejores par谩metros encontrados y se imprimen los resultados del modelo. Se visualiza el 谩rbol de decisi贸n resultante utilizando `plot_tree`.
     - **Evaluaci贸n de modelos**: Se entrena un modelo de Random Forest y se calculan las m茅tricas de evaluaci贸n (precisi贸n, recall, F1, AUC) y la matriz de confusi贸n. Se visualizan las caracter铆sticas m谩s importantes del modelo de Random Forest utilizando un gr谩fico de barras.
     - **Algoritmos adicionales**: Se implementa y eval煤a un modelo KNN (vecinos m谩s cercanos), calculando las m茅tricas de evaluaci贸n y visualizando la matriz de confusi贸n. Se implementa y eval煤a un modelo XGBoost, calculando las m茅tricas de evaluaci贸n y visualizando la matriz de confusi贸n. Se implementa y eval煤a un modelo SVM (M谩quinas de Soporte Vectorial), calculando las m茅tricas de evaluaci贸n y visualizando la matriz de confusi贸n.
     - **Evaluaciones con Cross Validation**: Se configuran m茅tricas de evaluaci贸n y se utiliza `StratifiedKFold` para realizar validaci贸n cruzada con 10 pliegues en los modelos Random Forest, KNN, SVM y XGBoost. Se imprimen los resultados de la validaci贸n cruzada para cada modelo, incluyendo precisi贸n, recall, F1 y AUC.
     - **Test estad铆stico Wilcoxon**: Se realizan pruebas estad铆sticas de Wilcoxon entre los modelos para comparar sus puntuaciones AUC en los 10 pliegues de validaci贸n cruzada. Se imprimen los resultados de las comparaciones, incluyendo los valores p para determinar la significancia estad铆stica de las diferencias entre los modelos.
